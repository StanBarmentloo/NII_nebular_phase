{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f274c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import add_funcs as af\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "from astropy.io import ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "\n",
    "M_sun = 1.989*10**33 #g\n",
    "pc = 3.086*10**18 #cm\n",
    "Mpc = 10**6 * pc\n",
    "c = 299792.458 #kms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the read in conditions and assumed values\n",
    "\n",
    "#This is the range which at least should be present to select the file\n",
    "lambda_min = 5000 #Å, have at least Mg I\n",
    "lambda_max = 8000 #Å\n",
    "\n",
    "nebular_start = 120 #days, define the start of the nebular phase\n",
    "nebular_end = 450 #days, define the end of the nebular phas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebb55b",
   "metadata": {},
   "source": [
    "## Read in the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3414b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_names = [\"NII_he3p30_AJ_10_90\", \"NII_he3p30_AJ_20_80\",\n",
    "                 \"NII_he3p30_AJ_30_70\", \"NII_he3p30_AJ_60_40\",\n",
    "                 \"NII_he4p00_AJ_10_90\", \"NII_he4p00_AJ_20_80\",\n",
    "                 \"NII_he4p00_AJ_30_70\", \"NII_he4p00_AJ_60_40\",\n",
    "                 \"NII_he6p00_AJ_10_90\", \"NII_he6p00_AJ_20_80\",\n",
    "                 \"NII_he6p00_AJ_30_70\", \"NII_he6p00_AJ_60_40\" ]\n",
    "\n",
    "core_percent = [10, 20, 30, 60, 10, 20, 30, 60, 10, 20, 30, 60]\n",
    "masses = [3.3, 3.3, 3.3, 3.3, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0]\n",
    "\n",
    "colours = ['blue', 'red', 'green'] #for the plotting\n",
    "zoom = [3500, 9500] #Give the region to be zoomed in at.\n",
    "\n",
    "deps = []\n",
    "wavelengths, fluxes, NII_fluxes = [], [], []\n",
    "\n",
    "for i in range(len(project_names)):\n",
    "    dep_path = \"/home/stba7609/Documents/Projects/300d/\" + project_names[i] + \"/out/main/dep.dat\"\n",
    "    data = open(dep_path, 'r')\n",
    "    \n",
    "    counter = 0\n",
    "    print(\"Mass & Core_percent:\", masses[i], core_percent[i])\n",
    "    for line in data:\n",
    "        if counter == 0:\n",
    "            deps.append(float(line))\n",
    "        counter += 1\n",
    "        \n",
    "    #===================================================================================================\n",
    "    spectrum_path = \"/home/stba7609/Documents/Projects/300d/\" + project_names[i] + \"/out/modelspectra/spectrum.datrun001\"\n",
    "    data = ascii.read(spectrum_path)\n",
    "    \n",
    "    wavelength_raw = data['col1'] #In Ångström\n",
    "    flux_raw = data['col2'] #In erg s-1 cm-2 Å-1\n",
    "    NII_flux_raw = data['col15'] #See ABIN Codes on github\n",
    "    \n",
    "    wavelength_raw = af.redshift_correct_wl(wavelength_raw, 10) #Correct redshift for models, which are all at 10 Mpc\n",
    "    \n",
    "    \n",
    "    relevant_index = np.where((wavelength_raw > 6450) * (wavelength_raw < 6700))[0][17]\n",
    "    highest, index = 0, 0\n",
    "    for i in range(6, 150):\n",
    "        col = 'col' + str(i)\n",
    "        val = data[col][relevant_index]\n",
    "        if val > highest:\n",
    "            highest = val\n",
    "            index = i\n",
    "    print(\"Fraction of NII radiation at peak & strongest emitting element: \", NII_flux_raw[relevant_index]/flux_raw[relevant_index], index)\n",
    "    \n",
    "    filter1 = (wavelength_raw < zoom[1])*(wavelength_raw > zoom[0])\n",
    "    \n",
    "    wavelength = wavelength_raw[filter1]\n",
    "    flux = flux_raw[filter1]\n",
    "    NII_flux = NII_flux_raw[filter1]\n",
    "    \n",
    "    wavelengths.append(wavelength)\n",
    "    fluxes.append(flux)\n",
    "    NII_fluxes.append(NII_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b874387",
   "metadata": {},
   "source": [
    "## Compare with the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd59bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(af.v_from_labda(6581, 6565))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f300a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Read in the data\n",
    "base_path = '/home/stba7609/Documents/Observations/'\n",
    "\n",
    "sn_names = np.array(['2007Y', '2008ax', '2011dh', '2013ge', 'iPTF13bvn',\n",
    "                    '1990I', '2004ao', '2004dk', '2004gq', '2007C',\n",
    "                    '2012au', '2014C', '2015Q'])\n",
    "expl_dates = np.array([2454146.50000, 2454528.50000, 2455712.50000, 2456605.50000, 2456460.50000,\n",
    "                      2447990.50000, 2453055.50000, 2453218.50000, 2453340.50000, 2454101.50000,\n",
    "                      2455987.50000, 2456651.50000, 2457190.50000])\n",
    "expl_dates_exact = np.array([True, True, True, True, True,\n",
    "                            False, False, False, False, False,\n",
    "                            False, False, False]) #If unkown, take 20 days before peaklight or at discovery (if either no peaklight given or further than 20 days before peak)\n",
    "\n",
    "vlines = np.array([3500, 4500, 3500, 3500, 3500,\n",
    "                  3500, 3500, 3500, 3500, 3500,\n",
    "                  3500, 3500, 3500]) #kms\n",
    "recession_velocities = np.array([0, 565, 600, 0 ,0,\n",
    "                                0, 0, 0, 0, 0,\n",
    "                                0, 0, 0]) #kms. 0 means the value is not known\n",
    "Ni_masses = np.array([0.075, 0.10, 0.075, 0.075, 0.075,\n",
    "                     0.075, 0.075, 0.075, 0.075, 0.075,\n",
    "                     0.075, 0.075, 0.075])*M_sun\n",
    "\n",
    "redshifts = np.array([0.004657 ,0.001931 ,0.002,0.004356,0.00449,\n",
    "                     0.009703, 0.005641, 0.0052, 0.006468, 0.005611,\n",
    "                     0.0045, 0.002722, 0.00792])\n",
    "distances = af.z_to_r(redshifts)*Mpc\n",
    "\n",
    "counter = 0\n",
    "\n",
    "epochs, NII_fluxes = [], []\n",
    "\n",
    "for i in range(len(sn_names)):\n",
    "    \n",
    "    #Read in the specific SN folder\n",
    "    sn_name = sn_names[i]\n",
    "    observations = os.listdir(path = base_path + sn_name )\n",
    "    \n",
    "    info_file = ascii.read(base_path + sn_name + '/wiserep_spectra.csv',\n",
    "                          delimiter = ',')\n",
    "    \n",
    "    expl_date = expl_dates[i]\n",
    "    \n",
    "    \n",
    "    #Now read each observation of that SN, get its integrated NII and store those\n",
    "    local_epochs = [] #days, time since explosion\n",
    "    local_NII_fluxes = []\n",
    "    for j in range(len(observations)-1):\n",
    "        \n",
    "        distance = distances[i]\n",
    "        vline = vlines[i]\n",
    "        M_Ni = Ni_masses[i]\n",
    "        recession_velocity = recession_velocities[i]\n",
    "        redshift = redshifts[i]\n",
    "        \n",
    "        #Make sure the file ticks all boxes to be considered a good spectrum\n",
    "        condition1 = (info_file['Lambda-min'][j] <= lambda_min)\n",
    "        condition2 = (info_file['Lambda-max'][j] >= lambda_max)\n",
    "        condition3 = (info_file['JD'][j]-expl_date >= nebular_start) \n",
    "        condition4 = (info_file['JD'][j]-expl_date <= nebular_end)\n",
    "        \n",
    "        \n",
    "        if condition1 and condition2 and condition3 and condition4:\n",
    "            counter += 1\n",
    "            \n",
    "            epoch = info_file['JD'][j]-expl_date\n",
    "            local_epochs.append(epoch)\n",
    "            \n",
    "            print(j, info_file['Ascii file'][j], info_file['JD'][j]-expl_date)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Read in the data\n",
    "            this_observation_data = np.loadtxt(base_path + sn_name + '/' + info_file['Ascii file'][j])\n",
    "            \n",
    "            \n",
    "            #Apply some normalisations\n",
    "            if (np.max(this_observation_data[:, 1]) < 7) *(np.max(this_observation_data[:, 1]) > 5.5):\n",
    "                wl, flux = af.redshift_correct_wl(this_observation_data[:, 0], own_z = redshift), this_observation_data[:, 1]/(2*10**15)\n",
    "            elif np.max(this_observation_data[:, 1]) > 10**-9:\n",
    "                wl, flux = af.redshift_correct_wl(this_observation_data[:, 0], own_z = redshift), this_observation_data[:, 1]/10**15\n",
    "            else:\n",
    "                wl, flux = af.redshift_correct_wl(this_observation_data[:, 0], own_z = redshift), this_observation_data[:, 1]\n",
    "                #wl = this_observation_data[:, 0]\n",
    "                \n",
    "                \n",
    "            #Compare to models\n",
    "            if abs(epoch-300) < 0:\n",
    "                \n",
    "                epoch_correction = np.exp(-2*(epoch-300)/111.4)\n",
    "                \n",
    "                for q in range(len(project_names)):\n",
    "                    \n",
    "                    if q < 4:\n",
    "                        model_ni = 0.0221 * M_sun\n",
    "                    elif q > 3 and q < 8:\n",
    "                        model_ni = 0.0187 * M_sun\n",
    "                    else:\n",
    "                        model_ni = 0.051 * M_sun\n",
    "                        \n",
    "                    Ni_correction = M_Ni/model_ni\n",
    "                    distance_correction = 1/(((distance/Mpc)/10)**2)\n",
    "                    total_correction = epoch_correction*Ni_correction*distance_correction\n",
    "                    \n",
    "                    \n",
    "                    print(distance/Mpc, ((distance/Mpc)/10)**2)\n",
    "                    plt.plot(wavelengths[q], fluxes[q]*total_correction, linestyle = '--', label = project_names[q]) #((distance/Mpc)/10)**2\n",
    "                    plt.plot(wl, flux, label = sn_name) #Correct for distance difference\n",
    "                    plt.legend()\n",
    "                    plt.show()\n",
    "            \n",
    "            #Integrate the fluxes\n",
    "            integrated_NII_flux_my_method, popt = af.observed_flux_from_fit(wl, flux, plot = True)\n",
    "            integrated_NII_flux_AJ = af.observed_flux_AJ(wl, flux, vline, 6300, 6363)\n",
    "            \n",
    "            surface = 4*np.pi*distance**2\n",
    "            true_integrated_NII_flux_my_method = integrated_NII_flux_my_method*surface\n",
    "            true_integrated_NII_flux_AJ = integrated_NII_flux_AJ*surface\n",
    "            \n",
    "            normalisation_mask = (wl > lambda_min) * (wl < lambda_max)\n",
    "            \n",
    "            #Change here\n",
    "            #OI_flux = af.gaussian(wl, 6316, popt[0], popt[2])\n",
    "            #my_normalisation = integrate.cumtrapz(OI_flux, wl)[-1]*surface\n",
    "            \n",
    "            my_normalisation = integrate.cumtrapz(flux[normalisation_mask], wl[normalisation_mask])[-1]*surface\n",
    "            \n",
    "            AJ_normalisation = af.Lnorm_AJ(epoch, M_Ni)\n",
    "            \n",
    "            print(\"The NII doublet carries: \", \"{0:.3g}\".format(true_integrated_NII_flux_my_method*100/my_normalisation), \"% of the selected region\")\n",
    "            print(\"The NII doublet carries: \", \"{0:.3g}\".format(true_integrated_NII_flux_my_method*100/AJ_normalisation), \"% of the selected region with AJ\")\n",
    "            \n",
    "            local_NII_fluxes.append(true_integrated_NII_flux_AJ/AJ_normalisation)\n",
    "            \n",
    "    epochs.append(local_epochs)\n",
    "    NII_fluxes.append(local_NII_fluxes)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1)    \n",
    "for k in range(len(NII_fluxes)):\n",
    "    ax.plot(np.array(epochs[k])[np.array(NII_fluxes[k]) < 1], np.array(NII_fluxes[k])[np.array(NII_fluxes[k]) < 1], label = sn_names[k])\n",
    "    \n",
    "ax.set_xlim(0, 600)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"The counter is: \", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87da02",
   "metadata": {},
   "source": [
    "## Find best fitting model for 2011dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sn_names)):\n",
    "    if i != 2:\n",
    "        pass\n",
    "    else:\n",
    "        #Read in the specific SN folder\n",
    "        sn_name = sn_names[i]\n",
    "        observations = os.listdir(path = base_path + sn_name )\n",
    "\n",
    "        info_file = ascii.read(base_path + sn_name + '/wiserep_spectra.csv',\n",
    "                              delimiter = ',')\n",
    "\n",
    "        expl_date = expl_dates[i]\n",
    "\n",
    "\n",
    "        #Now read each observation of that SN, get its integrated NII and store those\n",
    "        dh_epochs = [] #days, time since explosion\n",
    "        dh_wls, dh_fluxes = [], []\n",
    "        for j in range(len(observations)-1):\n",
    "\n",
    "            distance = distances[i]\n",
    "            vline = vlines[i]\n",
    "            M_Ni = Ni_masses[i]\n",
    "            recession_velocity = recession_velocities[i]\n",
    "            redshift = redshifts[i]\n",
    "\n",
    "            #Make sure the file ticks all boxes to be considered a good spectrum\n",
    "            condition1 = (info_file['Lambda-min'][j] <= lambda_min)\n",
    "            condition2 = (info_file['Lambda-max'][j] >= lambda_max)\n",
    "            condition3 = (info_file['JD'][j]-expl_date >= nebular_start) \n",
    "            condition4 = (info_file['JD'][j]-expl_date <= nebular_end)\n",
    "\n",
    "\n",
    "            if condition1 and condition2 and condition3 and condition4:\n",
    "                counter += 1\n",
    "\n",
    "                epoch = info_file['JD'][j]-expl_date\n",
    "                local_epochs.append(epoch)\n",
    "\n",
    "                print(j, info_file['Ascii file'][j], info_file['JD'][j]-expl_date)\n",
    "\n",
    "\n",
    "\n",
    "                #Read in the data\n",
    "                this_observation_data = np.loadtxt(base_path + sn_name + '/' + info_file['Ascii file'][j])\n",
    "\n",
    "\n",
    "                #Apply some normalisations\n",
    "                if (np.max(this_observation_data[:, 1]) < 7) *(np.max(this_observation_data[:, 1]) > 5.5):\n",
    "                    wl, flux = af.redshift_correct_wl(this_observation_data[:, 0], own_z = redshift), this_observation_data[:, 1]/(2*10**15)\n",
    "                elif np.max(this_observation_data[:, 1]) > 10**-9:\n",
    "                    wl, flux = af.redshift_correct_wl(this_observation_data[:, 0], own_z = redshift), this_observation_data[:, 1]/10**15\n",
    "                else:\n",
    "                    wl, flux = af.redshift_correct_wl(this_observation_data[:, 0], own_z = redshift), this_observation_data[:, 1]\n",
    "                    #wl = this_observation_data[:, 0]\n",
    "                    \n",
    "                dh_epochs.append(epoch)\n",
    "                dh_wls.append(wl)\n",
    "                dh_fluxes.append(flux)\n",
    "                \n",
    "                \n",
    "dh_epochs = np.array(dh_epochs)\n",
    "dh_wls = np.array(dh_wls)\n",
    "dh_fluxes = np.array(dh_fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_list_333070, flux_list_333070, flux_list_ca, flux_list_ni, flux_list_mg = [], [], [], [], []\n",
    "old_wl_list_333070, old_flux_list_333070, old_flux_list_ca, old_flux_list_ni, old_flux_list_mg = [], [], [], [], []\n",
    "\n",
    "string_mass, string_mixing = '4p00', '10_90'\n",
    "string_epochs = ['300d', '400d']#['200d', '250d', '300d', '350d', '400d']\n",
    "epochs = np.array([300, 400])#np.array([200, 250, 300, 350, 400])\n",
    "\n",
    "for l in range(len(string_epochs)):\n",
    "    \n",
    "    epoch = string_epochs[l]\n",
    "    model_name = '/NII_he' + string_mass + '_AJ_' + string_mixing\n",
    "    spectrum_path = \"/home/stba7609/Documents/Projects/SUMO_Projects_v1p0/\" + epoch + model_name + \"/out/modelspectra/spectrum.datrun001\"\n",
    "    data = ascii.read(spectrum_path)\n",
    "\n",
    "    wl_list_333070.append(data['col1'])\n",
    "    flux_list_333070.append(data['col2'])\n",
    "    flux_list_ca.append(data['col55'])\n",
    "    flux_list_ni.append(data['col71'])\n",
    "    \n",
    "#==========================================================\n",
    "for l in range(len(string_epochs)):\n",
    "    \n",
    "    epoch = string_epochs[l]\n",
    "    model_name = '/NII_he' + string_mass + '_AJ_' + string_mixing\n",
    "    spectrum_path = \"/home/stba7609/Documents/Projects/SUMO_Projects_v/\" + epoch + model_name + \"/out/modelspectra/spectrum.datrun001\"\n",
    "    data = ascii.read(spectrum_path)\n",
    "\n",
    "    old_wl_list_333070.append(data['col1'])\n",
    "    old_flux_list_333070.append(data['col2'])\n",
    "    old_flux_list_ca.append(data['col55'])\n",
    "    old_flux_list_ni.append(data['col71'])\n",
    "#==========================================================\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(5, 1)\n",
    "\n",
    "new_model_ni, old_model_ni, M_ni = 0.0612 * M_sun, 0.0445 * M_sun, 0.075 * M_sun #v1p0:0.0547, 0.0612, 0.0839 v:0.04, 0.0445, 0.0704\n",
    "sn_name = '2011dh'\n",
    "distance = 7.8*Mpc\n",
    "for k in range(len(string_epochs)):\n",
    "    \n",
    "    local_wl, local_flux, local_ca_flux, local_ni_flux = wl_list_333070[k], flux_list_333070[k], flux_list_ca[k], flux_list_ni[k]\n",
    "    old_local_wl, old_local_flux, old_local_ca_flux, old_local_ni_flux = old_wl_list_333070[k], old_flux_list_333070[k], old_flux_list_ca[k], old_flux_list_ni[k]\n",
    "    \n",
    "    \n",
    "    closest_index = np.argmin(abs(epochs[k]-dh_epochs))\n",
    "    closest_epoch = dh_epochs[closest_index]\n",
    "    closest_wl, closest_flux = dh_wls[closest_index], dh_fluxes[closest_index]\n",
    "    \n",
    "    epoch_correction = np.exp(-2*(closest_epoch-epochs[k])/111.4)\n",
    "    Ni_correction_new = M_Ni/new_model_ni\n",
    "    Ni_correction_old = M_Ni/old_model_ni\n",
    "    distance_correction = 1/(((distance/Mpc)/10)**2)\n",
    "    total_correction_new = epoch_correction*Ni_correction_new*distance_correction\n",
    "    total_correction_old = epoch_correction*Ni_correction_old*distance_correction\n",
    "    \n",
    "    ax[k].plot(local_wl, local_flux*total_correction_new, linestyle = '--', label = 'v1p0 model at ' + '{0:.0f}'.format(closest_epoch) + ' days.') \n",
    "    ax[k].plot(old_local_wl, old_local_flux*total_correction_old, linestyle = '--', label = 'v model at ' + '{0:.0f}'.format(closest_epoch) + ' days.') \n",
    "    \n",
    "    #ax[k].plot(local_wl, local_ca_flux*total_correction, linestyle = '--', label = 'caII at ' + '{0:.0f}'.format(closest_epoch) + ' days.')\n",
    "    #ax[k].plot(local_wl, local_ni_flux*total_correction, linestyle = '--', label = 'niII at ' + '{0:.0f}'.format(closest_epoch) + ' days.')\n",
    "    ax[k].plot(closest_wl, closest_flux, label = sn_name + ' at ' + '{0:.0f}'.format(closest_epoch) + ' days.')\n",
    "    ax[k].set_ylabel('Flux [erg s-1 cm-2]')\n",
    "    ax[k].legend(fontsize = 14)\n",
    "\n",
    "    #ax[k].set_xlim(7000, 7500)\n",
    "ax[-1].set_xlabel('Wavelength [Å]')\n",
    "fig.set_size_inches(15, 20)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Comparing_different_ff.png')\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb5512",
   "metadata": {},
   "source": [
    "## Find best fitting model for 2007Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b10c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sn_names)):\n",
    "    if i != 0:\n",
    "        pass\n",
    "    else:\n",
    "        #Read in the specific SN folder\n",
    "        sn_name = sn_names[i]\n",
    "        observations = os.listdir(path = base_path + sn_name )\n",
    "\n",
    "        info_file = ascii.read(base_path + sn_name + '/wiserep_spectra.csv',\n",
    "                              delimiter = ',')\n",
    "\n",
    "        expl_date = expl_dates[i]\n",
    "\n",
    "\n",
    "        #Now read each observation of that SN, get its integrated NII and store those\n",
    "        dh_epochs = [] #days, time since explosion\n",
    "        dh_wls, dh_fluxes = [], []\n",
    "        for j in range(len(observations)-1):\n",
    "\n",
    "            distance = distances[i]\n",
    "            vline = vlines[i]\n",
    "            M_Ni = Ni_masses[i]\n",
    "            recession_velocity = recession_velocities[i]\n",
    "            redshift = redshifts[i]\n",
    "\n",
    "            #Make sure the file ticks all boxes to be considered a good spectrum\n",
    "            condition1 = (info_file['Lambda-min'][j] <= lambda_min)\n",
    "            condition2 = (info_file['Lambda-max'][j] >= lambda_max)\n",
    "            condition3 = (info_file['JD'][j]-expl_date >= nebular_start) \n",
    "            condition4 = (info_file['JD'][j]-expl_date <= nebular_end)\n",
    "\n",
    "\n",
    "            if condition1 and condition2 and condition3 and condition4:\n",
    "                counter += 1\n",
    "\n",
    "                epoch = info_file['JD'][j]-expl_date\n",
    "                local_epochs.append(epoch)\n",
    "\n",
    "                print(j, info_file['Ascii file'][j], info_file['JD'][j]-expl_date)\n",
    "\n",
    "\n",
    "\n",
    "                #Read in the data\n",
    "                this_observation_data = np.loadtxt(base_path + sn_name + '/' + info_file['Ascii file'][j])\n",
    "\n",
    "\n",
    "                #Apply some normalisations\n",
    "                if (np.max(this_observation_data[:, 1]) < 7) *(np.max(this_observation_data[:, 1]) > 5.5):\n",
    "                    wl, flux = af.redshift_correct_wl(this_observation_data[:, 0], own_z = redshift), this_observation_data[:, 1]/(2*10**15)\n",
    "                elif np.max(this_observation_data[:, 1]) > 10**-9:\n",
    "                    wl, flux = af.redshift_correct_wl(this_observation_data[:, 0], own_z = redshift), this_observation_data[:, 1]/10**15\n",
    "                else:\n",
    "                    wl, flux = af.redshift_correct_wl(this_observation_data[:, 0], own_z = redshift), this_observation_data[:, 1]\n",
    "                    \n",
    "                dh_epochs.append(epoch)\n",
    "                dh_wls.append(wl)\n",
    "                dh_fluxes.append(flux)\n",
    "                \n",
    "                \n",
    "dh_epochs = np.array(dh_epochs)\n",
    "dh_wls = np.array(dh_wls)\n",
    "dh_fluxes = np.array(dh_fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf8cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_list_333070, flux_list_333070 = [], []\n",
    "\n",
    "string_mass, string_mixing = '3p30', '10_90'\n",
    "string_epochs = ['200d', '250d', '300d', '350d', '400d']\n",
    "epochs = np.array([200, 250, 300, 350, 400])\n",
    "\n",
    "for l in range(len(string_epochs)):\n",
    "    \n",
    "    epoch = string_epochs[l]\n",
    "    model_name = '/NII_he' + string_mass + '_AJ_' + string_mixing\n",
    "    spectrum_path = \"/home/stba7609/Documents/Projects/SUMO_Projects_v1p0\" + epoch + model_name + \"/out/modelspectra/spectrum.datrun001\"\n",
    "    data = ascii.read(spectrum_path)\n",
    "\n",
    "    wl_list_333070.append(data['col1'])\n",
    "    flux_list_333070.append(data['col2'])\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "model_ni, M_Ni = 0.04 * M_sun, 0.06* M_sun #v1p0:0.0547, 0.0612, 0.0839 v:0.04, 0.0445, 0.0704\n",
    "sn_name = '2007Y'\n",
    "distance = distances[0]\n",
    "print(distance/Mpc)\n",
    "for k in range(len(string_epochs)-2):\n",
    "    \n",
    "    local_wl, local_flux = wl_list_333070[k], flux_list_333070[k]\n",
    "    \n",
    "    closest_index = np.argmin(abs(epochs[k]-dh_epochs))\n",
    "    closest_epoch = dh_epochs[closest_index]\n",
    "    closest_wl, closest_flux = dh_wls[closest_index], dh_fluxes[closest_index]\n",
    "    \n",
    "    epoch_correction = np.exp(-2*(closest_epoch-epochs[k])/111.4)\n",
    "    Ni_correction = M_Ni/model_ni\n",
    "    distance_correction = 1/(((distance/Mpc)/10)**2)\n",
    "    total_correction = epoch_correction*Ni_correction*distance_correction\n",
    "    \n",
    "    ax[k].plot(local_wl, local_flux*total_correction, linestyle = '--', label = 'model at ' + '{0:.0f}'.format(closest_epoch) + ' days.') \n",
    "    ax[k].plot(closest_wl, closest_flux, label = sn_name + ' at ' + '{0:.0f}'.format(closest_epoch) + ' days.')\n",
    "    ax[k].set_ylabel('Flux [erg s-1 cm-2]')\n",
    "    ax[k].legend(fontsize = 14)\n",
    "\n",
    "\n",
    "ax[-1].set_xlabel('Wavelength [Å]')\n",
    "fig.set_size_inches(15, 20)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('he3p30_10_90_vs_2007Y_postupdate.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed762cd1",
   "metadata": {},
   "source": [
    "## Determine O I Linewidths in observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96660f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(af.v_from_labda(6555, 6563))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4736a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(3, len(sn_names)):\n",
    "    \n",
    "    #Read in the specific SN folder\n",
    "    sn_name = sn_names[i]\n",
    "    observations = os.listdir(path = base_path + sn_name )\n",
    "    \n",
    "    info_file = ascii.read(base_path + sn_name + '/wiserep_spectra.csv',\n",
    "                          delimiter = ',')\n",
    "    \n",
    "    expl_date = expl_dates[i]\n",
    "    \n",
    "    \n",
    "    #Now read each observation of that SN, get its integrated NII and store those\n",
    "    local_epochs = [] #days, time since explosion\n",
    "    local_NII_fluxes = []\n",
    "    local_velocities = []\n",
    "    for j in range(len(observations)-1):\n",
    "        \n",
    "        distance = distances[i]\n",
    "        vline = vlines[i]\n",
    "        M_Ni = Ni_masses[i]\n",
    "        recession_velocity = recession_velocities[i]\n",
    "        redshift = redshifts[i]\n",
    "        \n",
    "        #Make sure the file ticks all boxes to be considered a good spectrum\n",
    "        condition1 = (info_file['Lambda-min'][j] <= lambda_min)\n",
    "        condition2 = (info_file['Lambda-max'][j] >= lambda_max)\n",
    "        condition3 = (info_file['JD'][j]-expl_date >= nebular_start) \n",
    "        condition4 = (info_file['JD'][j]-expl_date <= nebular_end)\n",
    "        \n",
    "        \n",
    "        if condition1 and condition2 and condition3 and condition4:\n",
    "            counter += 1\n",
    "            \n",
    "            epoch = info_file['JD'][j]-expl_date\n",
    "            local_epochs.append(epoch)\n",
    "            \n",
    "            print(j, info_file['Ascii file'][j], info_file['JD'][j]-expl_date)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Read in the data\n",
    "            this_observation_data = np.loadtxt(base_path + sn_name + '/' + info_file['Ascii file'][j])\n",
    "            \n",
    "            wl, flux = af.redshift_correct_wl(this_observation_data[:, 0], own_z = redshift), this_observation_data[:, 1]\n",
    "            \n",
    "            integrated_NII_flux_my_method, popt = af.observed_flux_from_fit(wl, flux, plot = True)\n",
    "            \n",
    "            OI_velocity = af.v_from_labda(6316-2*popt[2], 6316)\n",
    "            local_velocities.append(OI_velocity)\n",
    "            \n",
    "    if sum(local_velocities) != 0:         \n",
    "        print(\"For SN \", sn_name, \" the typical OI velocities are:\", np.sort(local_velocities), \" with an average of: \", sum(local_velocities)/len(local_velocities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf2231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
